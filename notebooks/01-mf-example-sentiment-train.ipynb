{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a71464e-711e-4df0-974b-b2cbf9207a03",
   "metadata": {},
   "source": [
    "This shows you how to load the datasets and use them to train a sentiment classifier.\n",
    "The sentiment classifier that is trained is just replicating the existing sentiment classification that has been applied.\n",
    "\n",
    "The first thing to do is to review the dataset, and then we can train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ae0cd71-58aa-4fcd-932a-b601c9c42206",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path(\".\").resolve().parent\n",
    "MODEL_FOLDER = PROJECT_ROOT / \"models\"\n",
    "DATA_RAW_FOLDER = PROJECT_ROOT / \"data\" / \"raw\"\n",
    "\n",
    "# these are unique by the combination of title, text AND sentiment\n",
    "BURGER_KING_FILE = DATA_RAW_FOLDER / \"burger-king.csv\" # ~145k rows\n",
    "WENDYS_FILE = DATA_RAW_FOLDER / \"wendys.csv\" # ~50k rows\n",
    "\n",
    "MODEL_RUN_FOLDER = MODEL_FOLDER / \"example-sentiment\"\n",
    "MODEL_RUN_FOLDER.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "MODEL_NAME = \"bert-base-uncased\" # very small\n",
    "BATCH_SIZE = 8 # adjust to your RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96feed8c-7b55-4e7b-93bf-fc06260ab25d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @libsoftiktok $500 fine for burning down a ...</td>\n",
       "      <td>RT @libsoftiktok $500 fine for burning down a ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @RealSweet17 Do you think the punishment fi...</td>\n",
       "      <td>RT @RealSweet17 Do you think the punishment fi...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @CollinRugg JUST IN: Two rioters who were r...</td>\n",
       "      <td>RT @CollinRugg JUST IN: Two rioters who were r...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @charliekirk11 Whoa! More two-tiered justic...</td>\n",
       "      <td>RT @charliekirk11 Whoa! More two-tiered justic...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @RepMTG J6â€™ers are being locked up for year...</td>\n",
       "      <td>RT @RepMTG J6â€™ers are being locked up for year...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46232</th>\n",
       "      <td>@sara_ash88 when I was working hard on my weig...</td>\n",
       "      <td>@sara_ash88 when I was working hard on my weig...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46233</th>\n",
       "      <td>nigga dat work at wendys said ohh ik you and s...</td>\n",
       "      <td>nigga dat work at wendys said ohh ik you and s...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46234</th>\n",
       "      <td>ðŸ”† The sunny days are calling, and so is the bo...</td>\n",
       "      <td>ðŸ”† The sunny days are calling, and so is the bo...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46235</th>\n",
       "      <td>Cara the GM at edwardsville Wendy's</td>\n",
       "      <td>Cara the GM at edwardsville Wendy's</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46236</th>\n",
       "      <td>Beyond awful</td>\n",
       "      <td>so many reasons this app is awful, number one;...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46237 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0      RT @libsoftiktok $500 fine for burning down a ...   \n",
       "1      RT @RealSweet17 Do you think the punishment fi...   \n",
       "2      RT @CollinRugg JUST IN: Two rioters who were r...   \n",
       "3      RT @charliekirk11 Whoa! More two-tiered justic...   \n",
       "4      RT @RepMTG J6â€™ers are being locked up for year...   \n",
       "...                                                  ...   \n",
       "46232  @sara_ash88 when I was working hard on my weig...   \n",
       "46233  nigga dat work at wendys said ohh ik you and s...   \n",
       "46234  ðŸ”† The sunny days are calling, and so is the bo...   \n",
       "46235                Cara the GM at edwardsville Wendy's   \n",
       "46236                                       Beyond awful   \n",
       "\n",
       "                                                    text sentiment  \n",
       "0      RT @libsoftiktok $500 fine for burning down a ...   neutral  \n",
       "1      RT @RealSweet17 Do you think the punishment fi...  negative  \n",
       "2      RT @CollinRugg JUST IN: Two rioters who were r...  negative  \n",
       "3      RT @charliekirk11 Whoa! More two-tiered justic...  negative  \n",
       "4      RT @RepMTG J6â€™ers are being locked up for year...  negative  \n",
       "...                                                  ...       ...  \n",
       "46232  @sara_ash88 when I was working hard on my weig...  positive  \n",
       "46233  nigga dat work at wendys said ohh ik you and s...   neutral  \n",
       "46234  ðŸ”† The sunny days are calling, and so is the bo...   neutral  \n",
       "46235                Cara the GM at edwardsville Wendy's   neutral  \n",
       "46236  so many reasons this app is awful, number one;...  negative  \n",
       "\n",
       "[46237 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "wendys_df = pd.read_csv(WENDYS_FILE)\n",
    "\n",
    "# make it unique by text\n",
    "wendys_df = wendys_df.drop_duplicates(subset=\"text\")\n",
    "wendys_df = wendys_df.reset_index(drop=True)\n",
    "\n",
    "wendys_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472241db-2b93-42db-bd19-f8c8bf139533",
   "metadata": {},
   "source": [
    "The dataset is the title of the thread or article and the text around the match.\n",
    "For twitter the title is the same as the text except that the whitespace has been normalized.\n",
    "\n",
    "To train with this we need to generate a single text column and convert the sentiment into an index.\n",
    "We can just drop the title column as this is really a demonstration - you may wish to do something more sophisticated.\n",
    "To convert the sentiment into an index we can convert it into a [category](https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html).\n",
    "The category datatype is used for distinct values (like our positive/neutral/negative sentiment column) and creates a mapping between an integer value and the associated original value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b866c4dd-8397-47fc-a435-c51bf5b94dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @libsoftiktok $500 fine for burning down a ...</td>\n",
       "      <td>RT @libsoftiktok $500 fine for burning down a ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @RealSweet17 Do you think the punishment fi...</td>\n",
       "      <td>RT @RealSweet17 Do you think the punishment fi...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @CollinRugg JUST IN: Two rioters who were r...</td>\n",
       "      <td>RT @CollinRugg JUST IN: Two rioters who were r...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @charliekirk11 Whoa! More two-tiered justic...</td>\n",
       "      <td>RT @charliekirk11 Whoa! More two-tiered justic...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @RepMTG J6â€™ers are being locked up for year...</td>\n",
       "      <td>RT @RepMTG J6â€™ers are being locked up for year...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46232</th>\n",
       "      <td>@sara_ash88 when I was working hard on my weig...</td>\n",
       "      <td>@sara_ash88 when I was working hard on my weig...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46233</th>\n",
       "      <td>nigga dat work at wendys said ohh ik you and s...</td>\n",
       "      <td>nigga dat work at wendys said ohh ik you and s...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46234</th>\n",
       "      <td>ðŸ”† The sunny days are calling, and so is the bo...</td>\n",
       "      <td>ðŸ”† The sunny days are calling, and so is the bo...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46235</th>\n",
       "      <td>Cara the GM at edwardsville Wendy's</td>\n",
       "      <td>Cara the GM at edwardsville Wendy's</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46236</th>\n",
       "      <td>Beyond awful</td>\n",
       "      <td>so many reasons this app is awful, number one;...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46237 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0      RT @libsoftiktok $500 fine for burning down a ...   \n",
       "1      RT @RealSweet17 Do you think the punishment fi...   \n",
       "2      RT @CollinRugg JUST IN: Two rioters who were r...   \n",
       "3      RT @charliekirk11 Whoa! More two-tiered justic...   \n",
       "4      RT @RepMTG J6â€™ers are being locked up for year...   \n",
       "...                                                  ...   \n",
       "46232  @sara_ash88 when I was working hard on my weig...   \n",
       "46233  nigga dat work at wendys said ohh ik you and s...   \n",
       "46234  ðŸ”† The sunny days are calling, and so is the bo...   \n",
       "46235                Cara the GM at edwardsville Wendy's   \n",
       "46236                                       Beyond awful   \n",
       "\n",
       "                                                    text sentiment  label  \n",
       "0      RT @libsoftiktok $500 fine for burning down a ...   neutral      1  \n",
       "1      RT @RealSweet17 Do you think the punishment fi...  negative      0  \n",
       "2      RT @CollinRugg JUST IN: Two rioters who were r...  negative      0  \n",
       "3      RT @charliekirk11 Whoa! More two-tiered justic...  negative      0  \n",
       "4      RT @RepMTG J6â€™ers are being locked up for year...  negative      0  \n",
       "...                                                  ...       ...    ...  \n",
       "46232  @sara_ash88 when I was working hard on my weig...  positive      2  \n",
       "46233  nigga dat work at wendys said ohh ik you and s...   neutral      1  \n",
       "46234  ðŸ”† The sunny days are calling, and so is the bo...   neutral      1  \n",
       "46235                Cara the GM at edwardsville Wendy's   neutral      1  \n",
       "46236  so many reasons this app is awful, number one;...  negative      0  \n",
       "\n",
       "[46237 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wendys_df[\"sentiment\"] = wendys_df.sentiment.astype(\"category\")\n",
    "wendys_df[\"label\"] = wendys_df.sentiment.cat.codes\n",
    "label_to_sentiment = dict(enumerate(wendys_df.sentiment.cat.categories))\n",
    "\n",
    "wendys_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ee7afd7-5722-4eed-99bc-cf46feeece84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'negative', 1: 'neutral', 2: 'positive'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b011ff-b657-440f-92e6-3d5acb902190",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "The NLP model that we will use expects to receive tokens instead of text, which means we have to encode the text as well.\n",
    "\n",
    "Training on all 50k rows would take too long.\n",
    "Instead I am going to reduce this dataset to 1,000 rows for training, 100 for validation and 100 as a test set.\n",
    "Ideally the test set would come from a different dataset (the burger king posts might be good for this, they are still social media posts about restaurants though)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75f470c1-d22d-4dfb-8a00-f708721af79c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @libsoftiktok $500 fine for burning down a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @RealSweet17 Do you think the punishment fi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @CollinRugg JUST IN: Two rioters who were r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @charliekirk11 Whoa! More two-tiered justic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @RepMTG J6â€™ers are being locked up for year...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>@got_cake @Soulvintageone Damn that is scrimp!...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>@AMK_PhD @RepMTG He was married but fell aslee...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>@CollinRugg You people are more bent over not ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>@radicalricci Maâ€™am this is a Wendyâ€™s</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>@WallStreetSilv Shrinkflation is a real thing....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     RT @libsoftiktok $500 fine for burning down a ...      1\n",
       "1     RT @RealSweet17 Do you think the punishment fi...      0\n",
       "2     RT @CollinRugg JUST IN: Two rioters who were r...      0\n",
       "3     RT @charliekirk11 Whoa! More two-tiered justic...      0\n",
       "4     RT @RepMTG J6â€™ers are being locked up for year...      0\n",
       "...                                                 ...    ...\n",
       "1195  @got_cake @Soulvintageone Damn that is scrimp!...      0\n",
       "1196  @AMK_PhD @RepMTG He was married but fell aslee...      0\n",
       "1197  @CollinRugg You people are more bent over not ...      0\n",
       "1198              @radicalricci Maâ€™am this is a Wendyâ€™s      1\n",
       "1199  @WallStreetSilv Shrinkflation is a real thing....      1\n",
       "\n",
       "[1200 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wendys_df = wendys_df[[\"text\", \"label\"]]\n",
    "\n",
    "# 1k for training, 100 for validation, 100 for test\n",
    "wendys_df = wendys_df[:1_200]\n",
    "\n",
    "# â™¬ he's making a list,\n",
    "# he's checking it twice,\n",
    "# he's gonna find out,\n",
    "# who's setting on a copy of a slice â™¬\n",
    "wendys_df = wendys_df.copy()\n",
    "\n",
    "wendys_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea8d305e-ee13-4bf4-88e0-75115015c704",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca1ca745-c6f5-4762-9c05-692980ea3337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>input_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @libsoftiktok $500 fine for burning down a ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[101, 19387, 1030, 5622, 5910, 15794, 5480, 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @RealSweet17 Do you think the punishment fi...</td>\n",
       "      <td>0</td>\n",
       "      <td>[101, 19387, 1030, 2613, 26760, 15558, 16576, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @CollinRugg JUST IN: Two rioters who were r...</td>\n",
       "      <td>0</td>\n",
       "      <td>[101, 19387, 1030, 22180, 26549, 2290, 2074, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @charliekirk11 Whoa! More two-tiered justic...</td>\n",
       "      <td>0</td>\n",
       "      <td>[101, 19387, 1030, 4918, 23630, 2243, 14526, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @RepMTG J6â€™ers are being locked up for year...</td>\n",
       "      <td>0</td>\n",
       "      <td>[101, 19387, 1030, 16360, 20492, 2290, 1046, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>@got_cake @Soulvintageone Damn that is scrimp!...</td>\n",
       "      <td>0</td>\n",
       "      <td>[101, 1030, 2288, 1035, 9850, 1030, 3969, 6371...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>@AMK_PhD @RepMTG He was married but fell aslee...</td>\n",
       "      <td>0</td>\n",
       "      <td>[101, 1030, 2572, 2243, 1035, 8065, 1030, 1636...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>@CollinRugg You people are more bent over not ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[101, 1030, 22180, 26549, 2290, 2017, 2111, 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>@radicalricci Maâ€™am this is a Wendyâ€™s</td>\n",
       "      <td>1</td>\n",
       "      <td>[101, 1030, 7490, 7277, 6895, 5003, 1521, 2572...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>@WallStreetSilv Shrinkflation is a real thing....</td>\n",
       "      <td>1</td>\n",
       "      <td>[101, 1030, 3681, 13334, 3215, 4014, 2615, 228...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label  \\\n",
       "0     RT @libsoftiktok $500 fine for burning down a ...      1   \n",
       "1     RT @RealSweet17 Do you think the punishment fi...      0   \n",
       "2     RT @CollinRugg JUST IN: Two rioters who were r...      0   \n",
       "3     RT @charliekirk11 Whoa! More two-tiered justic...      0   \n",
       "4     RT @RepMTG J6â€™ers are being locked up for year...      0   \n",
       "...                                                 ...    ...   \n",
       "1195  @got_cake @Soulvintageone Damn that is scrimp!...      0   \n",
       "1196  @AMK_PhD @RepMTG He was married but fell aslee...      0   \n",
       "1197  @CollinRugg You people are more bent over not ...      0   \n",
       "1198              @radicalricci Maâ€™am this is a Wendyâ€™s      1   \n",
       "1199  @WallStreetSilv Shrinkflation is a real thing....      1   \n",
       "\n",
       "                                              input_ids  \n",
       "0     [101, 19387, 1030, 5622, 5910, 15794, 5480, 18...  \n",
       "1     [101, 19387, 1030, 2613, 26760, 15558, 16576, ...  \n",
       "2     [101, 19387, 1030, 22180, 26549, 2290, 2074, 1...  \n",
       "3     [101, 19387, 1030, 4918, 23630, 2243, 14526, 2...  \n",
       "4     [101, 19387, 1030, 16360, 20492, 2290, 1046, 2...  \n",
       "...                                                 ...  \n",
       "1195  [101, 1030, 2288, 1035, 9850, 1030, 3969, 6371...  \n",
       "1196  [101, 1030, 2572, 2243, 1035, 8065, 1030, 1636...  \n",
       "1197  [101, 1030, 22180, 26549, 2290, 2017, 2111, 20...  \n",
       "1198  [101, 1030, 7490, 7277, 6895, 5003, 1521, 2572...  \n",
       "1199  [101, 1030, 3681, 13334, 3215, 4014, 2615, 228...  \n",
       "\n",
       "[1200 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode(text: str) -> list[int]:\n",
    "    tokenized = tokenizer(\n",
    "        text,\n",
    "        return_attention_mask=False,\n",
    "        return_token_type_ids=False,\n",
    "    )\n",
    "    return tokenized.input_ids\n",
    "\n",
    "wendys_df[\"input_ids\"] = wendys_df.text.apply(encode)\n",
    "wendys_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a229c2c8-f661-4b35-b273-54703a78e269",
   "metadata": {},
   "source": [
    "At this point we have the dataset prepared.\n",
    "We need to split it into the train, valid and test sets.\n",
    "\n",
    "I am converting the dataframes into datasets here, which is a custom huggingface format.\n",
    "Converting the dataframes to a list of dictionaries would also work.\n",
    "The trainer does not work with the dataframes directly unfortunately.\n",
    "\n",
    "You can check the full documentation for the datasets library [here](https://huggingface.co/docs/datasets/index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bb9ed0b-c274-4f8b-9e8c-42e459fcc0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train_df = wendys_df[:1_000]\n",
    "valid_df = wendys_df[1_000:1_100]\n",
    "test_df = wendys_df[1_100:1_200]\n",
    "\n",
    "assert not (set(train_df.text) & set(valid_df.text)), \"rows shared between train and valid\"\n",
    "assert not (set(train_df.text) & set(test_df.text)), \"rows shared between train and test\"\n",
    "assert not (set(valid_df.text) & set(test_df.text)), \"rows shared between valid and test\"\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "valid_ds = Dataset.from_pandas(valid_df)\n",
    "test_ds = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f89586-22fc-4ecd-bb2d-84a5ad1419fd",
   "metadata": {},
   "source": [
    "When training we want to be able to see how well our model has trained.\n",
    "This can also be used to select the best model at the end of training.\n",
    "\n",
    "We can calculate the accuracy metric by comparing the predictions to the gold labels.\n",
    "There are many other metrics that may provide more detailed performance information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95859d04-0e2c-4f31-bad9-212b5b0bd7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EvalPrediction\n",
    "\n",
    "def compute_metrics(results: EvalPrediction) -> dict[str, float]:\n",
    "    predictions = results.predictions.argmax(axis=1)\n",
    "    targets = results.label_ids\n",
    "    correct = predictions == targets\n",
    "    return {\n",
    "        \"accuracy\": correct.mean(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16850cfa-24c5-48a4-a404-5b6374803b58",
   "metadata": {},
   "source": [
    "Now we can train the model.\n",
    "I don't know what sort of computer you have and I want this to run quickly so I have made the train _very short_.\n",
    "You can alter the max_steps and logging_steps to change how long the train is done for and how often the evaluation is run.\n",
    "\n",
    "Check the full documentation for the trainer [here](https://huggingface.co/docs/transformers/main_classes/trainer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f006cd3-e108-46a8-ba1f-a17843c0add8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/matthew/.cache/pypoetry/virtualenvs/fast-food-classifier-etipdf6R-py3.11/lib/python3.11/site-packages/transformers/training_args.py:1281: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of ðŸ¤— Transformers. Use `use_cpu` instead\n",
      "  warnings.warn(\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:47, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.977100</td>\n",
       "      <td>0.948106</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.828000</td>\n",
       "      <td>0.874752</td>\n",
       "      <td>0.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.875600</td>\n",
       "      <td>0.802535</td>\n",
       "      <td>0.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.694100</td>\n",
       "      <td>0.777884</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.724800</td>\n",
       "      <td>0.763196</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=50, training_loss=0.8199179649353028, metrics={'train_runtime': 48.6785, 'train_samples_per_second': 8.217, 'train_steps_per_second': 1.027, 'total_flos': 17595709810560.0, 'train_loss': 0.8199179649353028, 'epoch': 0.4})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from datasets import Dataset\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=3)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    learning_rate=5e-5,\n",
    "    warmup_ratio=0.06,\n",
    "\n",
    "    report_to=[],\n",
    "\n",
    "    # very short as this is a demonstration\n",
    "    evaluation_strategy=\"steps\",\n",
    "    max_steps=50,\n",
    "    logging_steps=10,\n",
    "    eval_steps=10,\n",
    "\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True,\n",
    "    \n",
    "    no_cuda=True, # let you run it on any machine\n",
    "\n",
    "    # output_dir is compulsory\n",
    "    logging_dir=MODEL_RUN_FOLDER / \"output\",\n",
    "    output_dir=MODEL_RUN_FOLDER / \"output\",\n",
    "    overwrite_output_dir=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=valid_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33de8068-67a7-4633-acec-0f677c561172",
   "metadata": {},
   "source": [
    "This has been trained for 8 (batch size) x 50 (steps) = 400 rows of data.\n",
    "We didn't even make it through one epoch.\n",
    "The model will not perform well, remember this is a demonstration!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff262e7-0eec-4271-8dec-5ea731df64e9",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "With our \"trained\" model we can now evaluate it.\n",
    "Here we are testing against our test dataset and using the sklearn classification report to describe the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92e87ae0-b17a-4571-b1bb-5997a5927d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "import pandas as pd\n",
    "\n",
    "@torch.inference_mode()\n",
    "def predict(model: AutoModelForSequenceClassification, tokens: list[int]) -> int:\n",
    "    tokens_tensor = torch.tensor(tokens)\n",
    "    tokens_tensor = tokens_tensor.to(model.device)\n",
    "    tokens_tensor = tokens_tensor[None] # add a batch dimension\n",
    "    \n",
    "    output = model(input_ids=tokens_tensor)\n",
    "    predictions = output.logits\n",
    "    return predictions.argmax().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ceaf19e4-5dec-45c2-afe2-deae94c67afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = test_df.input_ids.apply(lambda tokens: predict(model, tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cfd10aa-1f50-4a1b-bee0-5bc3166e663f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.76      0.78        49\n",
      "     neutral       0.72      0.85      0.78        46\n",
      "    positive       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.76       100\n",
      "   macro avg       0.51      0.53      0.52       100\n",
      "weighted avg       0.73      0.76      0.74       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\n",
    "    classification_report(\n",
    "        y_true=test_df.label.map(label_to_sentiment),\n",
    "        y_pred=predictions.map(label_to_sentiment),\n",
    "        zero_division=0,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8da34d3-6567-4c7a-93c8-3559206b9c3e",
   "metadata": {},
   "source": [
    "These results are **not** good and they show that the test dataset is wildly imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f9c9354-388f-4de3-8d24-e7046c1827c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "negative    489\n",
       "neutral     462\n",
       "positive     49\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.label.map(label_to_sentiment).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dcfe1d-0349-4ef8-b122-9d3dd834d813",
   "metadata": {},
   "source": [
    "We can see that the training dataset is very imbalanced as well.\n",
    "This has resulted in a model which doesn't properly predict positive.\n",
    "\n",
    "Fixing this would involve balancing the datasets correctly, and likely training for longer.\n",
    "\n",
    "You could also think about ways to make sure that the dataset is diverse.\n",
    "The rows in these datasets are ordered by time.\n",
    "This means that the distribution reflects the current conversation around Wendys at the time.\n",
    "If there is a crisis then the conversation will skew negative.\n",
    "Secondly the current theme of conversation may result in very similar posts by different people, ensuring that you have a diversity of topics would also improve the quality of your model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
